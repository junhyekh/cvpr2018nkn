{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from forward_kinematics import FK\n",
    "\n",
    "  # def mlp_out(self, input_, reuse=False, name=\"mlp_out\"):\n",
    "  #   out = qlinear(input_, 4 * (self.n_joints + 1), name=\"dec_fc\")\n",
    "  #   return out\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class EncoderDecoderGRU(object):\n",
    "  def __init__(self,\n",
    "               batch_size,\n",
    "               n_joints,\n",
    "               layers_units,\n",
    "               keep_prob,\n",
    "               ):\n",
    "\n",
    "    self.n_joints = n_joints\n",
    "    self.batch_size = batch_size\n",
    "    self.max_len=60\n",
    "    self.kp = keep_prob\n",
    "    self.layers_units=layers_units\n",
    "    self.fk=FK()\n",
    "    self.parents = np.array([\n",
    "      -1, 0, 1, 2, 3, 4, 0, 6, 7, 8, 0, 10, 11, 12, 3, 14, 15, 16, 3, 18, 19,\n",
    "      20\n",
    "  ])\n",
    "\n",
    "    self.gen=self.generator(layers_units)\n",
    "\n",
    "  def generator(self, layers_units):\n",
    "    enc_gru = self.gru_model(layers_units)\n",
    "    dec_gru = self.gru_model(layers_units)\n",
    "\n",
    "    seqA_ = tf.keras.Input(\n",
    "        shape=(self.max_len, 3 * self.n_joints + 4),\n",
    "        batch_size=self.batch_size,\n",
    "        name=\"seqA\")\n",
    "    skelA_ = tf.keras.Input(\n",
    "        shape=(self.max_len, 3 * self.n_joints),\n",
    "        batch_size=self.batch_size,\n",
    "        name=\"skelA_\")\n",
    "    skelB_ = tf.keras.Input(\n",
    "        shape=(self.max_len, 3 * self.n_joints),\n",
    "        batch_size=self.batch_size,\n",
    "        name=\"skelB\")\n",
    "\n",
    "    b_local = []\n",
    "    b_global = []\n",
    "    b_quats = []\n",
    "    a_local = []\n",
    "    a_global = []\n",
    "    a_quats = []\n",
    "\n",
    "    statesA_AB = []\n",
    "    statesB_AB = []\n",
    "    statesA_BA = []\n",
    "    statesB_BA = []\n",
    "    fc=tf.keras.layers.Dense(4 * (self.n_joints + 1))\n",
    "    for units in layers_units:\n",
    "      statesA_AB += [tf.zeros([self.batch_size, units])]\n",
    "      statesB_AB += [tf.zeros([self.batch_size, units])]\n",
    "      statesA_BA += [tf.zeros([self.batch_size, units])]\n",
    "      statesB_BA += [tf.zeros([self.batch_size, units])]\n",
    "    print(statesA_AB)\n",
    "    print(seqA_[:, 0, :])\n",
    "    print(seqA_.shape, tf.expand_dims(seqA_[:, 0, :], 1).shape)\n",
    "    for t in range(self.max_len):\n",
    "      \"\"\"Retarget A to B\"\"\"       \n",
    "      ptA_in = seqA_[:, t, :]\n",
    "\n",
    "      n = enc_gru(tf.expand_dims(ptA_in, 1), initial_state=statesA_AB)\n",
    "      statesA_AB=n[1:]\n",
    "      if t == 0:\n",
    "        ptB_in = tf.zeros([self.batch_size, 3 * self.n_joints + 4])\n",
    "      else:\n",
    "        ptB_in = tf.concat([b_local[-1], b_global[-1]], axis=-1)\n",
    "\n",
    "      ptcombined = tf.concat(\n",
    "          values=[skelB_[:, 0, 3:], ptB_in, statesA_AB[-1]], axis=1)\n",
    "      print(ptcombined.shape)\n",
    "      n = dec_gru(tf.expand_dims(ptcombined, 1), initial_state=statesB_AB)\n",
    "      statesB_AB=n[1:]\n",
    "      angles_n_offset = fc(statesB_AB[-1])\n",
    "      output_angles = tf.reshape(angles_n_offset[:, :-4],\n",
    "                                  [self.batch_size, self.n_joints, 4])\n",
    "      b_global.append(angles_n_offset[:, -4:])\n",
    "      b_quats.append(self.normalized(output_angles))\n",
    "\n",
    "      skel_in = tf.reshape(skelB_[:, 0, :], [self.batch_size, self.n_joints, 3])\n",
    "      skel_in = skel_in \n",
    "\n",
    "      output = (self.fk.run(self.parents, skel_in, output_angles))\n",
    "      output = tf.reshape(output, [self.batch_size, -1])\n",
    "      b_local.append(output)\n",
    "      \"\"\"Retarget B back to A\"\"\"\n",
    "      ptB_in = tf.concat([b_local[-1], b_global[-1]], axis=-1)\n",
    "\n",
    "      n= enc_gru(tf.expand_dims(ptB_in, 1), initial_state=statesB_BA)\n",
    "      statesB_BA=n[1:]\n",
    "\n",
    "      if t == 0:\n",
    "        ptA_in = tf.zeros([self.batch_size, 3 * self.n_joints + 4])\n",
    "      else:\n",
    "        ptA_in = tf.concat([a_local[-1], a_global[-1]], axis=-1)\n",
    "\n",
    "      ptcombined = tf.concat(\n",
    "          values=[skelA_[:, 0, 3:], ptA_in, statesB_BA[-1]], axis=1)\n",
    "      n = dec_gru(tf.expand_dims(ptcombined, 1), initial_state=statesA_BA)\n",
    "      statesA_BA=n[1:]\n",
    "      angles_n_offset = fc(statesA_BA[-1])\n",
    "      output_angles = tf.reshape(angles_n_offset[:, :-4],\n",
    "                                [self.batch_size, self.n_joints, 4])\n",
    "      a_global.append(angles_n_offset[:, -4:])\n",
    "      a_quats.append(self.normalized(output_angles))\n",
    "\n",
    "      skel_in = tf.reshape(skelA_[:, 0, :], [self.batch_size, self.n_joints, 3])\n",
    "      skel_in = skel_in \n",
    "\n",
    "      output = (self.fk.run(self.parents, skel_in, output_angles))\n",
    "      output = tf.reshape(output, [self.batch_size, -1])\n",
    "      a_local.append(output)\n",
    "\n",
    "      return tf.keras.Model(inputs=[seqA_, skelA_, skelB_], outputs=[b_local, b_global, b_quats, a_local, a_global, a_quats]) \n",
    "      \n",
    "  def gru_model(self, layers_units, rnn_type=\"GRU\"):\n",
    "    gru_cells = [tf.keras.layers.GRUCell(units, dropout=(1-self.kp)) for units in layers_units]\n",
    "    gru_layer=tf.keras.layers.RNN(gru_cells, return_state=True)\n",
    "    return gru_layer\n",
    "  def normalized(self, angles):\n",
    "    lengths = tf.math.sqrt(tf.math.reduce_sum(tf.math.square(angles), axis=-1))\n",
    "    return angles / lengths[..., None]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "layers_units = []\n",
    "for i in range(2):\n",
    "    layers_units.append(512)\n",
    "gru=EncoderDecoderGRU(16, 22, layers_units, 0.9)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<tf.Tensor: shape=(16, 512), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>, <tf.Tensor: shape=(16, 512), dtype=float32, numpy=\n",
      "array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>]\n",
      "Tensor(\"strided_slice_157:0\", shape=(16, 70), dtype=float32)\n",
      "(16, 60, 70) (16, 1, 70)\n",
      "(16, 645)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}